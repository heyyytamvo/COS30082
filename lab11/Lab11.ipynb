{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Install Required Libraries"
      ],
      "metadata": {
        "id": "fKtoRYM38Rrt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F4C1ss88NQU",
        "outputId": "cbcd80d4-00dd-430c-e1b5-5635e22593a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
      ],
      "metadata": {
        "id": "CHTQN4Fm_J4q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Your Data"
      ],
      "metadata": {
        "id": "4suiQ7yR8YWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your questions, context, and answers\n",
        "context = \"The capital of France is Paris. The largest planet is Jupiter. William Shakespeare wrote 'Hamlet'. The boiling point of water is 100 degrees Celsius.\"\n",
        "questions = [\n",
        "    \"What is the capital of France?\",\n",
        "    \"What is the largest planet?\",\n",
        "    \"Who wrote 'Hamlet'?\",\n",
        "    \"What is the boiling point of water?\"\n",
        "]\n",
        "\n",
        "answers = [\n",
        "    \"Paris\",\n",
        "    \"Jupiter\",\n",
        "    \"William Shakespeare\",\n",
        "    \"100 degrees Celsius\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "KeVfhn4f8ZNl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Libraries"
      ],
      "metadata": {
        "id": "2RjaGTMj8dMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "from torch.utils.data import Dataset\n"
      ],
      "metadata": {
        "id": "FFgxVvLH8exn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize the Data"
      ],
      "metadata": {
        "id": "9kDtQSHQ8n93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Function to find start and end positions of answers\n",
        "def find_answer_positions(context, answer):\n",
        "    start_idx = context.find(answer)\n",
        "    end_idx = start_idx + len(answer)\n",
        "    return start_idx, end_idx\n",
        "\n",
        "# Create a list to hold the start and end positions\n",
        "start_positions = []\n",
        "end_positions = []\n",
        "\n",
        "for answer in answers:\n",
        "    start, end = find_answer_positions(context, answer)\n",
        "    start_positions.append(start)\n",
        "    end_positions.append(end)\n",
        "\n",
        "# Tokenize the questions and context\n",
        "encodings = tokenizer(\n",
        "    questions,\n",
        "    text_pair=[context] * len(questions),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Add start and end positions to the encodings\n",
        "encodings['start_positions'] = torch.tensor(start_positions)\n",
        "encodings['end_positions'] = torch.tensor(end_positions)"
      ],
      "metadata": {
        "id": "e4UG5rY7-hMy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Dataset Class"
      ],
      "metadata": {
        "id": "RG7AqyOa8ual"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Dataset class\n",
        "class QADataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "# Create the dataset\n",
        "dataset = QADataset(encodings)"
      ],
      "metadata": {
        "id": "uykG4m4E8wRq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "90es3Trq82Ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training arguments without WandB\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=64,\n",
        "    per_device_train_batch_size=2,\n",
        "    logging_dir='./logs',\n",
        "    report_to='none',  # Disable WandB logging\n",
        "    dataloader_pin_memory=False  # Disable pin_memory\n",
        ")\n",
        "\n",
        "# Create the Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "UclINHzI86Yg",
        "outputId": "9be642de-e179-4994-e4d1-62ae924a89f7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [128/128 00:04, Epoch 64/64]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=128, training_loss=0.00047957332571968436, metrics={'train_runtime': 4.1052, 'train_samples_per_second': 62.36, 'train_steps_per_second': 31.18, 'total_flos': 2809041650688.0, 'train_loss': 0.00047957332571968436, 'epoch': 64.0})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions"
      ],
      "metadata": {
        "id": "wcyno58W88Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question):\n",
        "    inputs = tokenizer(question, context, return_tensors='pt').to(device)  # Move inputs to the correct device\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Get the start and end logits\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "\n",
        "    # Find the positions of the highest logits\n",
        "    start_index = torch.argmax(start_logits).item()\n",
        "    end_index = torch.argmax(end_logits).item()\n",
        "\n",
        "    # Extract the answer\n",
        "    answer_tokens = inputs['input_ids'][0][start_index:end_index + 1]\n",
        "    answer = tokenizer.decode(answer_tokens)\n",
        "\n",
        "    return answer.strip()"
      ],
      "metadata": {
        "id": "HkLzb3dv9E47"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function\n",
        "print(answer_question(\"What is the capital of France?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NexThp5W9Gz-",
        "outputId": "c57d68f2-9097-44cd-c3ee-edb766245cb9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "' hamlet '. the boiling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function\n",
        "print(answer_question(\"Who wrote 'Hamlet'?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SH2X94X9Ldc",
        "outputId": "5ce5471c-3b27-4bb9-93a4-b20f4844ab75"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "' hamlet '. the boiling\n"
          ]
        }
      ]
    }
  ]
}